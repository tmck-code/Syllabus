{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need this for this demo to even be possible,\n",
    "# turns out that jupyter already runs in its own\n",
    "#  event loop which is NOT pretty to deal with\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "import asyncio\n",
    "\n",
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "print(requests.get(\"http://0.0.0.0:8080\").text)\n",
    "input()\n",
    "print(requests.get(\"http://0.0.0.0:8080/items\").text[:1000])\n",
    "input()\n",
    "print(requests.get(\"http://0.0.0.0:8080/items/1\").text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(6500):\n",
    "    print(requests.get(\"http://0.0.0.0:8080/items/1\").text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aiohttp import request\n",
    "import asyncio\n",
    "\n",
    "async def req(i):\n",
    "    async with request(\"get\", f\"http://0.0.0.0:8080/items/{i}\") as r:\n",
    "        print(await r.content.read())\n",
    "\n",
    "asyncio.run(req(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from throttler import Throttler\n",
    "\n",
    "async def req(i, t: Throttler):\n",
    "    print(i, \"starting\")\n",
    "    async with t:\n",
    "        print(i, \"inside throttler\")\n",
    "        async with request(\"get\", f\"http://0.0.0.0:8080/items/{i}\") as r:\n",
    "            print(i, \"before request\")\n",
    "            resp = await r.content.read()\n",
    "            print(i, \"after request\")\n",
    "            return resp\n",
    "\n",
    "t = Throttler(rate_limit=60, period=10.0)\n",
    "results = asyncio.run(asyncio.gather(*[asyncio.create_task(req(i, t)) for i in range(70)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tenacity import retry, stop_after_attempt, before_log\n",
    "\n",
    "from throttler import Throttler\n",
    "\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(stream=sys.stderr, level=logging.DEBUG)\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# @retry(stop=stop_after_attempt(3), before=before_log(logger, logging.DEBUG))\n",
    "@retry(stop=stop_after_attempt(3))\n",
    "async def req(i, t: Throttler):\n",
    "    async with t:\n",
    "        async with request(\"get\", f\"http://0.0.0.0:8080/items/{i}\") as r:\n",
    "            resp = await r.content.read()\n",
    "            r.raise_for_status()\n",
    "            return resp\n",
    "\n",
    "def run_reqs(rate_limit: int, period: float, n_reqs: int):\n",
    "    t = Throttler(rate_limit=rate_limit, period=period)\n",
    "    asyncio.run(asyncio.gather(*[asyncio.create_task(req(i, t)) for i in range(n_reqs)]))\n",
    "\n",
    "def run_reqs_2(rate_limit: int, period: float, n_reqs: int):\n",
    "    t = Throttler(rate_limit=rate_limit, period=period)\n",
    "    tasks = [req(i, t) for i in range(n_reqs)]\n",
    "\n",
    "async def testr(n):\n",
    "    return n\n",
    "\n",
    "def create_tasks(n):\n",
    "    tasks = [asyncio.create_task(testr(i)) for i in range(n)]\n",
    "\n",
    "def create_tasks_2(n):\n",
    "    tasks = [testr(i) for i in range(n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %memit run_reqs(10, 1.0, 1000)\n",
    "%memit run_reqs_2(10, 1.0, 1000)\n",
    "# %memit run_reqs_3(10, 1.0, 1000)\n",
    "%memit create_tasks(1000)\n",
    "%memit create_tasks(5000)\n",
    "%memit create_tasks(20_000)\n",
    "%memit run_reqs_2(10, 1.0, 20_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import time\n",
    "\n",
    "class ThrottledQueue(asyncio.Queue):\n",
    "    \"subclass asyncio.Queue i.e. import all behaviour\"\n",
    "\n",
    "    def __init__(self, per_second, debug=False, maxsize=0, *, loop=None, i=0):\n",
    "        \"Set up some extra vars and then call the original init\"\n",
    "\n",
    "        self.lock = asyncio.Lock()\n",
    "        self.i = i\n",
    "        self.per_second = per_second\n",
    "        self.last_get = time.time() # this is the fastest way... I think?\n",
    "        self.debug = debug\n",
    "        super(ThrottledQueue, self).__init__(maxsize=maxsize, loop=loop)\n",
    "\n",
    "    async def notify(self):\n",
    "        \"\"\"\n",
    "        Signals to the queue that an item is being retried, \n",
    "        so pause any get()s by aquiring the lock and throttling before releasing\n",
    "        \"\"\"\n",
    "        async with self.lock:\n",
    "            await self._throttle()\n",
    "\n",
    "    async def lock(self, n_seconds: int):\n",
    "        async with self.lock:\n",
    "            await asyncio.sleep(n_seconds)\n",
    "\n",
    "    async def get(self):\n",
    "        async with self.lock:\n",
    "            await self._throttle()\n",
    "            result = await super(ThrottledQueue, self).get()\n",
    "\n",
    "            self.last_get = time.time()\n",
    "            return result\n",
    "\n",
    "    async def retry(self):\n",
    "        async with self.lock:\n",
    "            await self._throttle()\n",
    "\n",
    "    async def _throttle(self):\n",
    "        elapsed = time.time() - self.last_get\n",
    "        sleep_time = (1/float(self.per_second)) - elapsed\n",
    "        if self.debug:\n",
    "            print(self.i, '- times', f'{elapsed:.5f}', '+', f'{sleep_time:.5f}', '=', self.per_second, '- sizes', self.qsize(), f'{self.qsize() / max(1, self.maxsize):.5f}')\n",
    "        await asyncio.sleep(max(0, sleep_time)) # Make sure we wait at least 0 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import sys\n",
    "from aiohttp import ClientResponseError\n",
    "\n",
    "class Sentinel: pass\n",
    "\n",
    "async def get_all_items(q, cntr: Counter):\n",
    "    async with request(\"get\", \"http://0.0.0.0:8080/items\") as r:\n",
    "        resp = await r.read()\n",
    "        r.raise_for_status()\n",
    "        cntr[\"success\"] += 1\n",
    "        for i, d in enumerate(json.loads(resp)):\n",
    "            await q.put((i, d))\n",
    "        await q.put((i, Sentinel))\n",
    "\n",
    "\n",
    "async def handle_error(e, q):\n",
    "    print(f\"HANDLING ERROR: {e}\")\n",
    "    if e.status == 429:\n",
    "        q.retry()\n",
    "    elif e.status == 503:\n",
    "        q.lock(10)\n",
    "\n",
    "async def item_worker(q, idx, cntr: Counter, ostream = sys.stdout):\n",
    "    retrying = False\n",
    "    while True:\n",
    "        if not retrying:\n",
    "            i, d = await q.get()\n",
    "        if d == Sentinel:\n",
    "            await q.put((i, Sentinel))\n",
    "            print(f\"worker {idx} exiting\")\n",
    "            return\n",
    "        try:\n",
    "            # TODO: actually retry lol, don't just pop a fresh item\n",
    "            async with request(\"get\", f\"http://0.0.0.0:8080/items/{d}\") as req:\n",
    "                resp = await req.read()\n",
    "                req.raise_for_status()\n",
    "                print(f\"worker {idx} response for #{i}: {resp}\", file=ostream)\n",
    "                cntr[\"success\"] += 1\n",
    "        except ClientResponseError as e:\n",
    "            await handle_error(e, q)\n",
    "\n",
    "def gen_req(idx): pass\n",
    "\n",
    "def run(per_second, n_workers=10, ostream=sys.stdout, debug=False):\n",
    "    cntr = Counter()\n",
    "    q = ThrottledQueue(per_second=per_second, maxsize=1000, debug=debug)\n",
    "    asyncio.run(\n",
    "        asyncio.gather(\n",
    "            asyncio.create_task(get_all_items(q, cntr)),\n",
    "            *[asyncio.create_task(item_worker(q, i, cntr, ostream)) for i in range(n_workers)],\n",
    "        )\n",
    "    )\n",
    "    return cntr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ThrottledQueue' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_16522/507459458.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_16522/2208687614.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(per_second, n_workers, ostream, debug)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mper_second\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mostream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0mcntr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     \u001b[0mq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mThrottledQueue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mper_second\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mper_second\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m     asyncio.run(\n\u001b[1;32m     52\u001b[0m         asyncio.gather(\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ThrottledQueue' is not defined"
     ]
    }
   ],
   "source": [
    "run(100, n_workers=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"results.txt\", \"w\") as ostream:\n",
    "    run(per_second=100, n_workers=100, ostream=ostream, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run(per_second=100, n_workers=10, debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fill the Queue beforehand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import sys\n",
    "from aiohttp import ClientResponseError\n",
    "\n",
    "class Sentinel: pass\n",
    "\n",
    "async def get_all_items(q, cntr: Counter):\n",
    "    async with request(\"get\", \"http://0.0.0.0:8080/items\") as r:\n",
    "        resp = await r.read()\n",
    "        r.raise_for_status()\n",
    "        cntr[\"success\"] += 1\n",
    "        for i, d in enumerate(json.loads(resp)):\n",
    "            await q.put((i, d))\n",
    "        await q.put((i, Sentinel))\n",
    "\n",
    "\n",
    "async def handle_error(e, q):\n",
    "    print(f\"HANDLING ERROR: {e}\")\n",
    "    if e.status == 429:\n",
    "        q.retry()\n",
    "    elif e.status == 503:\n",
    "        q.lock(10)\n",
    "\n",
    "async def item_worker(q, idx, cntr: Counter, ostream = sys.stdout):\n",
    "    while True:\n",
    "        i, d = await q.get()\n",
    "        if d == Sentinel:\n",
    "            await q.put((i, Sentinel))\n",
    "            print(f\"worker {idx} exiting\")\n",
    "            return\n",
    "        try:\n",
    "            async with request(\"get\", f\"http://0.0.0.0:8080/items/{d}\") as req:\n",
    "                resp = await req.read()\n",
    "                req.raise_for_status()\n",
    "                print(f\"worker {idx} response for #{i}: {resp}\", file=ostream)\n",
    "                cntr[\"success\"] += 1\n",
    "        except ClientResponseError as e:\n",
    "            await handle_error(e, q)\n",
    "\n",
    "def run(per_second, n_workers=10, ostream=sys.stdout, debug=False):\n",
    "    cntr = Counter()\n",
    "    q = ThrottledQueue(per_second=per_second, maxsize=1000, debug=debug)\n",
    "    asyncio.run(\n",
    "        asyncio.gather(\n",
    "            asyncio.create_task(get_all_items(q, cntr)),\n",
    "            *[asyncio.create_task(item_worker(q, i, cntr, ostream)) for i in range(n_workers)],\n",
    "        )\n",
    "    )\n",
    "    return cntr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "async def fill_queue(q, items):\n",
    "    for idx, i in enumerate(items):\n",
    "        await q.put((idx, i))\n",
    "    await q.put((idx, Sentinel))\n",
    "    return q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import count\n",
    "\n",
    "async def _unpack_queue(q):\n",
    "    l = list()\n",
    "    for idx in count():\n",
    "        i, d = await q.get()\n",
    "        if d == Sentinel:\n",
    "            print(\"exiting\")\n",
    "            return l\n",
    "        l.append(d)\n",
    "    return l\n",
    "\n",
    "def unpack_queue(q):\n",
    "    return asyncio.run(asyncio.create_task(_unpack_queue(q)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = asyncio.run(fill_queue(asyncio.Queue(), list(range(1000))))\n",
    "\n",
    "print(q.qsize(), sys.getsizeof(q))\n",
    "\n",
    "l = unpack_queue(q)\n",
    "\n",
    "print(q.qsize(), sys.getsizeof(q), sys.getsizeof(l), q.qsize(), len(l))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A more complete example\n",
    "\n",
    "- Logging before/after request\n",
    "- Stats collection\n",
    "  - Request duration\n",
    "  - Number of retries\n",
    "  - Errors received\n",
    "- Rate limited/throttled requests\n",
    "  - Ability to throttle ALL coroutines on demand (e.g. 503)\n",
    "- Custom error handlers\n",
    "- Custom request builders (build endpoint URL/request data from something like an endpoint ID)\n",
    "- Be able to join multiple consumers/producers together with Queue in between\n",
    "  - Or just have a single consumer working on a single queue and printing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import sys\n",
    "from aiohttp import ClientResponseError\n",
    "\n",
    "class Sentinel: pass\n",
    "\n",
    "async def get_all_items(q, cntr: Counter):\n",
    "    async with request(\"get\", \"http://0.0.0.0:8080/items\") as r:\n",
    "        resp = await r.read()\n",
    "        r.raise_for_status()\n",
    "        cntr[\"success\"] += 1\n",
    "        for i, d in enumerate(json.loads(resp)):\n",
    "            await q.put((i, d))\n",
    "        await q.put((i, Sentinel))\n",
    "\n",
    "\n",
    "async def handle_error(e, q):\n",
    "    print(f\"HANDLING ERROR: {e}\")\n",
    "    if e.status == 429:\n",
    "        q.retry()\n",
    "    elif e.status == 503:\n",
    "        q.lock(10)\n",
    "\n",
    "async def item_worker(q, idx, cntr: Counter, ostream = sys.stdout):\n",
    "    retrying = False\n",
    "    while True:\n",
    "        if not retrying:\n",
    "            i, d = await q.get()\n",
    "        if d == Sentinel:\n",
    "            await q.put((i, Sentinel))\n",
    "            print(f\"worker {idx} exiting\")\n",
    "            return\n",
    "        try:\n",
    "            # TODO: actually retry lol, don't just pop a fresh item\n",
    "            async with request(\"get\", f\"http://0.0.0.0:8080/items/{d}\") as req:\n",
    "                resp = await req.read()\n",
    "                req.raise_for_status()\n",
    "                print(f\"worker {idx} response for #{i}: {resp}\", file=ostream)\n",
    "                cntr[\"success\"] += 1\n",
    "        except ClientResponseError as e:\n",
    "            await handle_error(e, q)\n",
    "\n",
    "def gen_req(idx): pass\n",
    "\n",
    "def run(per_second, n_workers=10, ostream=sys.stdout, debug=False):\n",
    "    cntr = Counter()\n",
    "    q = ThrottledQueue(per_second=per_second, maxsize=1000, debug=debug)\n",
    "    asyncio.run(\n",
    "        asyncio.gather(\n",
    "            asyncio.create_task(get_all_items(q, cntr)),\n",
    "            *[asyncio.create_task(item_worker(q, i, cntr, ostream)) for i in range(n_workers)],\n",
    "        )\n",
    "    )\n",
    "    return cntr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
