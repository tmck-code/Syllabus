{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9cfefd37-a378-42f0-b0dc-3b479bbaec1e",
   "metadata": {},
   "source": [
    "# Lesson 04: Concurrency & Parallelism"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88cb23b1",
   "metadata": {},
   "source": [
    "## 0. Waiting\n",
    "\n",
    "No-one wants to wait! In programming, waiting == lost time and performance.\n",
    "\n",
    "1. CPU bound (waiting on computation)\n",
    "    - use parallelism\n",
    "    - e.g. iterate through very large file & transform to different format\n",
    "2. IO bound (waiting for hard disk or network)\n",
    "    - sending http request\n",
    "    - writing data to disk\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b999bdd-43f0-4854-b4c7-616a05484547",
   "metadata": {},
   "source": [
    "## 1. CPU Bound (Parallelism)\n",
    "\n",
    "Compared to concurrency, parallelism is easier to use, and is _usually_ easier to think about and design. Unfortunately, it's less commonly needed, as CPU bound processes usually only occur in certain scenarios, aka\n",
    "\n",
    "> **Big Data processing**\n",
    "\n",
    "### Data processing example\n",
    "\n",
    "We can explore this through a data-processing scenario: generating large JSON lines to write to file\n",
    "\n",
    "- This could be a transform of original files -> a more suitable format for insights\n",
    "- Manipulating database dumps (postgres/ES)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4aaed91",
   "metadata": {},
   "source": [
    "### Example 1: Threading\n",
    "\n",
    "*do some main work, and some work on the side!*\n",
    "\n",
    "1. We need to generate a _very_ large NDJSON file (newline-delimited JSON). For simplicities sake, all lines are readable/same schema etc.\n",
    "\n",
    "    ```json\n",
    "    {\"a\": \"B\"}\n",
    "    {\"a\": \"C\"}\n",
    "    ```\n",
    "\n",
    "    1. There are many language and OS-level optimisations around doing the _exact_ same thing, like performing the same calculation over the same file line data. This means that we have to randomise the values in order to make a good test file.\n",
    "\n",
    "\n",
    "2. use `faker`! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e6af7de-b21f-4443-a90c-98ec77e96e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from faker import (Faker, providers)\n",
    "F = Faker()\n",
    "F.add_provider(providers.misc)\n",
    "F.add_provider(providers.geo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b818fc6-b32d-4593-8a7d-52128e90e316",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fkr_n(fkr, n):\n",
    "    return [fkr() for _ in range(n)]\n",
    "\n",
    "def gen_movie(f=F, indent=None):\n",
    "    \"Generates a fake movie listing\"\n",
    "\n",
    "    return json.dumps(\n",
    "        {\n",
    "            \"titleId\":         f.uuid4(),\n",
    "            \"ordering\":        f.random_int(),\n",
    "            \"title\":           f.catch_phrase(),\n",
    "            \"region\":          f.locale(),\n",
    "            \"language\":        f.language_name(),\n",
    "            \"types\":           fkr_n(f.name, 5),\n",
    "            \"attributes\":      fkr_n(f.name, 5),\n",
    "            \"isOriginalTitle\": f.boolean(),\n",
    "            \"tconst\":          f.uuid4(),\n",
    "            \"titleType\":       f.domain_name(),\n",
    "            \"primaryTitle\":    f.catch_phrase(),\n",
    "            \"originalTitle\":   \":\".join([f.company(), f.catch_phrase()]),\n",
    "            \"isAdult\":         f.boolean(),\n",
    "            \"startYear\":       f.date(),\n",
    "            \"endYear\":         f.year(),\n",
    "            \"runtimeMinutes\":  f.random_int(),\n",
    "            \"genres\":          fkr_n(f.country, 5),\n",
    "            \"tconst\":          f.hex_color(),\n",
    "            \"directors\":       fkr_n(f.name, 2),\n",
    "            \"writers\":         fkr_n(f.name, 15),\n",
    "            \"actors\":          fkr_n(f.name, 50),\n",
    "        },\n",
    "        indent=indent\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f22dfa23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pygments import highlight, lexers, formatters\n",
    "\n",
    "def pretty_print_json(j):\n",
    "    print(highlight(j, lexers.JsonLexer(), formatters.TerminalFormatter()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cae05daa-f21f-449c-82d1-c7682bc7aae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \u001b[94m\"titleId\"\u001b[39;49;00m: \u001b[33m\"fb739f2c-c596-426f-b9e7-6b56af487404\"\u001b[39;49;00m,\n",
      "  \u001b[94m\"ordering\"\u001b[39;49;00m: \u001b[34m1832\u001b[39;49;00m,\n",
      "  \u001b[94m\"title\"\u001b[39;49;00m: \u001b[33m\"Up-sized tangible knowledge user\"\u001b[39;49;00m,\n",
      "  \u001b[94m\"region\"\u001b[39;49;00m: \u001b[33m\"fur_IT\"\u001b[39;49;00m,\n",
      "  \u001b[94m\"language\"\u001b[39;49;00m: \u001b[33m\"Estonian\"\u001b[39;49;00m,\n",
      "  \u001b[94m\"types\"\u001b[39;49;00m: [\n",
      "    \u001b[33m\"Andrew Jenkins Jr.\"\u001b[39;49;00m,\n",
      "    \u001b[33m\"Franklin Perez\"\u001b[39;49;00m,\n",
      "    \u001b[33m\"Aaron Smith\"\u001b[39;49;00m,\n",
      "    \u001b[33m\"Cynthia Leon\"\u001b[39;49;00m,\n",
      "    \u001b[33m\"Christina Lucero\"\u001b[39;49;00m\n",
      "  ],\n",
      "  \u001b[94m\"attributes\"\u001b[39;49;00m: [\n",
      "    \u001b[33m\"Allison Rogers\"\u001b[39;49;00m,\n",
      "    \u001b[33m\"Kathy Leonard\"\u001b[39;49;00m,\n",
      "    \u001b[33m\"Krista Frye\"\u001b[39;49;00m,\n",
      "    \u001b[33m\"James Boyer\"\u001b[39;49;00m,\n",
      "    \u001b[33m\"Nicole Lin\"\u001b[39;49;00m\n",
      "  ],\n",
      "  \u001b[94m\"isOriginalTitle\"\u001b[39;49;00m: \u001b[34mfalse\u001b[39;49;00m,\n",
      "  \u001b[94m\"tconst\"\u001b[39;49;00m: \u001b[33m\"#b8a855\"\u001b[39;49;00m,\n",
      "  \u001b[94m\"titleType\"\u001b[39;49;00m: \u001b[33m\"jackson.com\"\u001b[39;49;00m,\n",
      "  \u001b[94m\"primaryTitle\"\u001b[39;49;00m: \u001b[33m\"Operative bandwidth-monitored initiative\"\u001b[39;49;00m,\n",
      "  \u001b[94m\"originalTitle\"\u001b[39;49;00m: \u001b[33m\"Mason-Mills:Phased client-driven frame\"\u001b[39;49;00m,\n",
      "  \u001b[94m\"isAdult\"\u001b[39;49;00m: \u001b[34mtrue\u001b[39;49;00m,\n",
      "  \u001b[94m\"startYear\"\u001b[39;49;00m: \u001b[33m\"1979-02-25\"\u001b[39;49;00m,\n",
      "  \u001b[94m\"endYear\"\u001b[39;49;00m: \u001b[33m\"2002\"\u001b[39;49;00m,\n",
      "  \u001b[94m\"runtimeMinutes\"\u001b[39;49;00m: \u001b[34m816\u001b[39;49;00m,\n",
      "  \u001b[94m\"genres\"\u001b[39;49;00m: [\n",
      "    \u001b[33m\"Mongolia\"\u001b[39;49;00m,\n",
      "    \u001b[33m\"Brazil\"\u001b[39;49;00m,\n",
      "    \u001b[33m\"Colombia\"\u001b[39;49;00m,\n",
      "    \u001b[33m\"Bahamas\"\u001b[39;49;00m,\n",
      "    \u001b[33m\"Botswana\"\u001b[39;49;00m\n",
      "  ],\n",
      "  \u001b[94m\"directors\"\u001b[39;49;00m: [\n",
      "    \u001b[33m\"Lisa Navarro\"\u001b[39;49;00m,\n",
      "    \u001b[33m\"Nicole Herman\"\u001b[39;49;00m\n",
      "  ],\n",
      "  \u001b[94m\"writers\"\u001b[39;49;00m: [\n",
      "    \u001b[33m\"Michael Wilson\"\u001b[39;49;00m,\n",
      "    \u001b[33m\"Sarah Jenkins\"\u001b[39;49;00m,\n",
      "    \u001b[33m\"Emily Chambers\"\u001b[39;49;00m,\n",
      "    \u001b[33m\"Emily Harrison\"\u001b[39;49;00m,\n",
      "    \u001b[33m\"Theresa Harrison\"\u001b[39;49;00m,\n",
      "    \u001b[33m\"William Adams\"\u001b[39;49;00m,\n",
      "    \u001b[33m\"Eileen Miller\"\u001b[39;49;00m,\n",
      "    \u001b[33m\"Ronald Johnson\"\u001b[39;49;00m,\n",
      "    \u001b[33m\"Gary Phillips\"\u001b[39;49;00m,\n",
      "    \u001b[33m\"Kristina Barber\"\u001b[39;49;00m,\n",
      "    \u001b[33m\"Karen Vazquez\"\u001b[39;49;00m,\n",
      "    \u001b[33m\"David Parsons\"\u001b[39;49;00m,\n",
      "    \u001b[33m\"Anthony Harvey\"\u001b[39;49;00m,\n",
      "    \u001b[33m\"Shannon Bradley\"\u001b[39;49;00m,\n",
      "    \u001b[33m\"Erin Clark\"\u001b[39;49;00m\n",
      "  ],\n",
      "  \u001b[94m\"actors\"\u001b[39;49;00m: [\n",
      "    \u001b[33m\"Joy Smith\"\u001b[39;49;00m,\n",
      "    \u001b[33m\"Dr. Marissa Benitez DVM\"\u001b[39;49;00m,\n",
      "    \u001b[33m\"Katherine Simon MD\"\u001b[39;49;00m,\n",
      "    \u001b[33m\"Brenda Graham\"\u001b[39;49;00m,\n",
      "    \u001b[33m\"Mary Powell\"\u001b[39;49;00m,\n",
      "    \u001b[33m\"Eric Mack\"\u001b[39;49;00m,\n",
      "    \u001b[33m\"Kenneth Cabrera\"\u001b[39;49;00m,\n",
      "    \u001b[33m\"Paul Hill\"\u001b[39;49;00m,\n",
      "    \u001b[33m\"Raymond Moran\"\u001b[39;49;00m,\n",
      "    \u001b[33m\"Sheena Ramirez\"\u001b[39;49;00m,\n",
      "    \u001b[33m\"Kevin Cooper\"\u001b[39;49;00m,\n",
      "    \u001b[33m\"Bradley Crane\"\u001b[39;49;00m,\n",
      "    \u001b[33m\"Jack Lucas\"\u001b[39;49;00m,\n",
      "    \u001b[33m\"Susan Wheeler\"\u001b[39;49;00m,\n",
      "    \u001b[33m\"Cindy Smith\"\u001b[39;49;00m,\n",
      "    \u001b[33m\"Christopher Henderson\"\u001b[39;49;00m,\n",
      "    \u001b[33m\"Chris Reyes\"\u001b[39;49;00m,\n",
      "    \u001b[33m\"Felicia Robinson\"\u001b[39;49;00m,\n",
      "    \u001b[33m\"William Smith\"\u001b[39;49;00m,\n",
      "    \u001b[33m\"Crystal Allen\"\u001b[39;49;00m,\n",
      "    \u001b[33m\"Nicolas Hughes\"\u001b[39;49;00m,\n",
      "    \u001b[33m\"Heather Huff\"\u001b[39;49;00m,\n",
      "    \u001b[33m\"Julia Willis\"\u001b[39;49;00m,\n",
      "    \u001b[33m\"Kayla Newton\"\u001b[39;49;00m,\n",
      "    \u001b[33m\"Rebecca Cross\"\u001b[39;49;00m,\n",
      "    \u001b[33m\"Jose Nunez\"\u001b[39;49;00m,\n",
      "    \u001b[33m\"Christy White\"\u001b[39;49;00m,\n",
      "    \u001b[33m\"Joshua Wilson\"\u001b[39;49;00m,\n",
      "    \u001b[33m\"Julia Garcia\"\u001b[39;49;00m,\n",
      "    \u001b[33m\"Zachary Juarez\"\u001b[39;49;00m,\n",
      "    \u001b[33m\"Vanessa Morrison\"\u001b[39;49;00m,\n",
      "    \u001b[33m\"Patricia Fitzgerald\"\u001b[39;49;00m,\n",
      "    \u001b[33m\"Rebecca Hernandez\"\u001b[39;49;00m,\n",
      "    \u001b[33m\"Ryan Wood\"\u001b[39;49;00m,\n",
      "    \u001b[33m\"Timothy Davidson\"\u001b[39;49;00m,\n",
      "    \u001b[33m\"Heather Walton\"\u001b[39;49;00m,\n",
      "    \u001b[33m\"Mark Lynch\"\u001b[39;49;00m,\n",
      "    \u001b[33m\"Dylan Munoz MD\"\u001b[39;49;00m,\n",
      "    \u001b[33m\"Devin Stone\"\u001b[39;49;00m,\n",
      "    \u001b[33m\"Christopher Hardin\"\u001b[39;49;00m,\n",
      "    \u001b[33m\"Jordan Martinez\"\u001b[39;49;00m,\n",
      "    \u001b[33m\"Traci Morales\"\u001b[39;49;00m,\n",
      "    \u001b[33m\"Nicole Wyatt\"\u001b[39;49;00m,\n",
      "    \u001b[33m\"Dale Mclaughlin\"\u001b[39;49;00m,\n",
      "    \u001b[33m\"Eric Clark\"\u001b[39;49;00m,\n",
      "    \u001b[33m\"Alicia Jenkins\"\u001b[39;49;00m,\n",
      "    \u001b[33m\"Marcus Rogers\"\u001b[39;49;00m,\n",
      "    \u001b[33m\"Jonathan Jordan\"\u001b[39;49;00m,\n",
      "    \u001b[33m\"Stacey Lynch\"\u001b[39;49;00m,\n",
      "    \u001b[33m\"Frank Lyons\"\u001b[39;49;00m\n",
      "  ]\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pretty_print_json(gen_movie(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ecf39df-2168-4231-8530-72516a1e7b1c",
   "metadata": {},
   "source": [
    "Woohoo! Now we just need to write this to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "851dfbf4-7d81-4e31-8a36-56944a564bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovieTable:\n",
    "    def records(fpath, n_records=10):\n",
    "        \"Writes random movies to a file\"\n",
    "\n",
    "        print(f\"Writing {n_records} records to {fpath}\")\n",
    "        with open(fpath, \"w\") as ostream:\n",
    "            for _ in range(n_records):\n",
    "                print(gen_movie(), file=ostream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87e5bf97-93ba-427b-8f4e-97beb3b939a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 200 records to /tmp/movies.ndjson\n"
     ]
    }
   ],
   "source": [
    "MovieTable.records(\"/tmp/movies.ndjson\", 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bbec93f-5a10-46ca-919e-c03902e467a5",
   "metadata": {},
   "source": [
    "Now let's introduce another process - a monitor that will tell us how much CPU we are currently using\n",
    "\n",
    "> Use psutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74bea59e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\t0.0\t0.0\t0.0\t0.0\t0.0\n"
     ]
    }
   ],
   "source": [
    "import psutil\n",
    "def cpu(*args):\n",
    "    print(\"\\t\".join(map(str, psutil.cpu_percent(percpu=True))))\n",
    "\n",
    "cpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce13c5d2",
   "metadata": {},
   "source": [
    "Now, let's experiment with running some sort of loop, and _also_ running our CPU checker.\n",
    "\n",
    "Let's try `threading`! This is the most basic entrypoint into async programming in python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b45191d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "1.9\t2.9\t8.5\t1.9\t3.8\t2.9\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "import time\n",
    "\n",
    "def loop_with_timer(n):\n",
    "    timer = threading.Timer(1, cpu)\n",
    "    timer.start()\n",
    "\n",
    "    # Actually do stuff here\n",
    "    for i in range(n):\n",
    "        print(i)\n",
    "        time.sleep(1)\n",
    "\n",
    "    timer.cancel()\n",
    "\n",
    "# If we run this, we should see a CPU check every second?\n",
    "loop_with_timer(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe74dba",
   "metadata": {},
   "source": [
    "Huh? The threading. Timer only printed once?!\n",
    "\n",
    "- The \"interval\" of the timer is more like a \"delay\"   \n",
    "- from the docs:\n",
    "    ```\n",
    "    \"Create a timer that will run function with arguments args and keyword arguments kwargs, \n",
    "    after interval seconds have passed.\"\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7157877f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1.6\t1.4\t2.0\t2.4\t1.6\t1.6\n",
      "1\n",
      "3.1\t1.0\t4.0\t5.9\t4.1\t5.1\n",
      "2\n",
      "3.1\t4.0\t4.0\t5.1\t2.0\t11.1\n",
      "3\n",
      "4\n",
      "7.0\t5.0\t2.0\t6.9\t5.9\t15.8\n"
     ]
    }
   ],
   "source": [
    "# Shout out -> https://stackoverflow.com/a/48741004\n",
    "class RepeatTimer(threading.Timer):\n",
    "    def run(self):\n",
    "        while not self.finished.wait(self.interval):\n",
    "            self.function(*self.args, **self.kwargs)\n",
    "\n",
    "def loop_with_timer(n):\n",
    "    timer = RepeatTimer(1, cpu)\n",
    "    timer.start()\n",
    "\n",
    "    for i in range(n):\n",
    "        print(i)\n",
    "        time.sleep(1)\n",
    "\n",
    "    timer.cancel()\n",
    "\n",
    "loop_with_timer(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67bdc755",
   "metadata": {},
   "source": [
    "Hmmm, there's a downside here -   \n",
    "In every function that we want to track CPU usage for, we have to add all of this threading code which is pretty icky\n",
    "\n",
    "However - we could make a decorator function that would allow anything to be timed just by adding a `@decoration`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "02825ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "\n",
    "def with_cpu(func):\n",
    "    'Looks gross, but you only have to write it once!'\n",
    "\n",
    "    @functools.wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        # Start the timer\n",
    "        timer = RepeatTimer(1, cpu, args=None, kwargs=None)\n",
    "        timer.start()\n",
    "\n",
    "        # Do thing\n",
    "        result = func(*args, **kwargs)\n",
    "\n",
    "        # Stop timer\n",
    "        timer.cancel()\n",
    "        print(\"wrapper fin!\")\n",
    "        return result\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bda1a64",
   "metadata": {},
   "source": [
    "Now, we can just add `@with_cpu` to any function that we need to investigate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "160c61c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "@with_cpu\n",
    "def poc():\n",
    "    for i in range(5):\n",
    "        print(i)\n",
    "        time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6bd68fae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "11.2\t15.1\t6.5\t4.4\t2.2\t4.7\n",
      "1\n",
      "3.1\t9.4\t11.5\t3.1\t3.0\t9.5\n",
      "2\n",
      "3\n",
      "0.0\t0.0\t1.0\t1.0\t0.0\t0.0\n",
      "4\n",
      "0.0\t0.0\t1.0\t0.0\t1.0\t1.0\n",
      "wrapper fin!0.0\t0.0\t1.0\t1.0\t4.1\t1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "poc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25978890",
   "metadata": {},
   "source": [
    "Let's add the decorator to our `MovieTable.records` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0e3aeea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovieTable:\n",
    "\n",
    "    @with_cpu\n",
    "    def records(fpath, n_records=10):\n",
    "        print(f\"Writing {n_records} records to {fpath}\")\n",
    "        with open(fpath, \"w\") as ostream:\n",
    "            for _ in range(n_records):\n",
    "                print(gen_movie(), file=ostream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e669530d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 500 records to /tmp/movies.ndjson\n",
      "1.7\t5.1\t5.0\t2.5\t89.0\t3.4\n",
      "1.0\t0.0\t0.0\t0.0\t100.0\t1.0\n",
      "0.0\t2.0\t0.0\t0.0\t100.0\t2.9\n",
      "2.0\t5.0\t2.0\t2.9\t99.0\t3.0\n",
      "1.0\t1.0\t0.0\t0.0\t100.0\t0.0\n",
      "0.0\t2.0\t1.0\t0.0\t100.0\t0.0\n",
      "0.0\t1.0\t1.0\t0.0\t100.0\t1.0\n",
      "wrapper fin!\n"
     ]
    }
   ],
   "source": [
    "MovieTable.records(\"/tmp/movies.ndjson\", 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64f8214",
   "metadata": {},
   "source": [
    "Nice!\n",
    "\n",
    "- Now we're running some code, an running another looping bit of code in a thread on the side.\n",
    "- We can see that we are currently using 1 core, and that core is running at 100%\n",
    "\n",
    "### What about `async`?\n",
    "\n",
    "1. `asyncio` give more control over when threads switch\n",
    "2. there is more code to write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c2ec4561-a162-4968-88a2-5897c0f58b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import asyncio\n",
    "from dataclasses import dataclass\n",
    "\n",
    "# Need this for this demo to even be possible,\n",
    "# turns out that jupyter already runs in its own\n",
    "#  event loop which is NOT pretty to deal with\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "@dataclass\n",
    "class Timer:\n",
    "    f:        object\n",
    "    id:       int  = 1\n",
    "    sentinel: bool = False\n",
    "\n",
    "    def task(self):\n",
    "        \"Starts the timer\"\n",
    "        return asyncio.create_task(self._run())\n",
    "\n",
    "    async def stop(self):\n",
    "        \"Stops the timer. This is the magic! Cancelling/force-halting things in async is not nice\"\n",
    "        self.sentinel = True\n",
    "\n",
    "    async def _run(self):\n",
    "        while not self.sentinel:\n",
    "            self.f(self.id)\n",
    "            await asyncio.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0a45c46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def run_with_timer(f: object, t: Timer):\n",
    "    t.task()       # Start timer\n",
    "    await f        # Do thing\n",
    "    await t.stop() # Stop timer, otherwise it will run forever\n",
    "    print(\"async timer fin!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4139c8b7",
   "metadata": {},
   "source": [
    "Now that we have our async timer, we also have to write an async version of AMovieTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "75822a40-5374-47a0-9512-fc9046df9531",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AMovieTable:\n",
    "    async def records(fpath, n_records=10):\n",
    "        print(f\"Writing {n_records} records to {fpath}\")\n",
    "        with open(fpath, \"w\") as ostream:\n",
    "            for _ in range(n_records):\n",
    "                print(gen_movie(), file=ostream) # Do work\n",
    "                await asyncio.sleep(0)           # Yield control to another thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7996b881-e88a-47e6-a24d-a25c3e3d64a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 500 records to /tmp/movies.ndjson\n",
      "7.4\t14.7\t3.3\t3.3\t82.3\t8.5\n",
      "6.9\t5.9\t6.9\t0.0\t100.0\t7.8\n",
      "9.7\t8.7\t14.6\t9.9\t100.0\t9.9\n",
      "0.0\t1.0\t1.9\t0.0\t100.0\t1.9\n",
      "1.0\t5.9\t1.9\t2.0\t100.0\t2.0\n",
      "0.0\t0.0\t1.0\t0.0\t100.0\t0.0\n",
      "1.0\t6.8\t4.0\t5.1\t100.0\t6.9\n",
      "async timer fin!\n"
     ]
    }
   ],
   "source": [
    "asyncio.run(\n",
    "    run_with_timer(\n",
    "        AMovieTable.records(\"/tmp/movies.ndjson\", 500),\n",
    "        Timer(cpu)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f04891",
   "metadata": {},
   "source": [
    "Cool, cool. How could we do the same thing, but with a decorator?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "66d46424",
   "metadata": {},
   "outputs": [],
   "source": [
    "def awith_cpu(func):\n",
    "    @functools.wraps(func)\n",
    "    async def wrapped(*args, **kwargs):\n",
    "        t = Timer(cpu)\n",
    "        t.task()\n",
    "\n",
    "        await func(*args, **kwargs)\n",
    "\n",
    "        await t.stop()\n",
    "        print(\"async dec fin!\")\n",
    "    return wrapped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5ddeb960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 500 records to /tmp/movies.ndjson\n",
      "15.8\t19.6\t10.6\t9.8\t73.2\t17.9\n",
      "2.9\t2.9\t1.9\t3.0\t100.0\t4.9\n",
      "0.0\t1.0\t0.0\t1.0\t100.0\t1.9\n",
      "0.0\t2.9\t0.0\t1.0\t100.0\t1.9\n",
      "1.9\t3.9\t1.9\t1.0\t99.1\t1.9\n",
      "1.0\t8.9\t2.0\t6.0\t100.0\t2.0\n",
      "1.0\t3.0\t1.0\t8.3\t100.0\t9.0\n",
      "3.8\t0.9\t0.0\t2.9\t95.4\t3.7\n",
      "async dec fin!\n"
     ]
    }
   ],
   "source": [
    "class AMovieTable:\n",
    "    @awith_cpu\n",
    "    async def records(fpath, n_records=10):\n",
    "        print(f\"Writing {n_records} records to {fpath}\")\n",
    "        with open(fpath, \"w\") as ostream:\n",
    "            for _ in range(n_records):\n",
    "                print(gen_movie(), file=ostream) # Do work\n",
    "                await asyncio.sleep(0)           # Yield control to another thread\n",
    "\n",
    "# This is much neater than the previous version\n",
    "# asyncio.run(\n",
    "#     run_with_timer(\n",
    "#         AMovieTable.records(\"/tmp/movies.ndjson\", 500),\n",
    "#         Timer(cpu)\n",
    "#     )\n",
    "# )\n",
    "asyncio.run(\n",
    "    AMovieTable.records(\"/tmp/movies.ndjson\", 500)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "68a2c7ab-b01a-4552-8139-2387f65f17b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 /tmp/movies.ndjson\n",
      "-rw-r--r-- 1 jovyan users 941K Dec  1 14:54 /tmp/movies.ndjson\n",
      "{\"titleId\": \"85d9e48b-d910-475d-97b4-27698dbc76e9\", \"ordering\": 2980, \"title\": \"Right-sized tertiary"
     ]
    }
   ],
   "source": [
    "!wc -l \"/tmp/movies.ndjson\" && ls -alh \"/tmp/movies.ndjson\" && head -c 100 \"/tmp/movies.ndjson\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708106ef",
   "metadata": {},
   "source": [
    "## Faster? -> multiprocessing\n",
    "\n",
    "Now that we have saturated the usage on a single core, let's run this on more cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fd036493-4c7f-48d3-b6c3-c7d515c8ccb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 500 records to /tmp/movies.ndjson\n",
      "Writing 500 records to /tmp/movies2.ndjson\n",
      "65.0\t9.0\t44.5\t9.5\t59.8\t16.8\n",
      "65.3\t9.3\t44.7\t9.5\t60.0\t16.7\n",
      "100.0\t4.2\t100.0\t4.0\t100.0\t7.1\n",
      "100.0\t3.1\t100.0\t5.9\t99.0\t6.9\n",
      "100.0\t3.0\t99.0\t9.9\t99.0\t3.9\n",
      "99.0\t3.0\t99.0\t10.0\t100.0\t5.0\n",
      "99.0\t2.0\t100.0\t8.6\t100.0\t3.8100.0\t2.0\t100.0\t6.8\t99.0\t2.9\n",
      "\n",
      "99.0\t1.0\t99.0\t7.8\t100.0\t6.999.0\t1.0\t99.0\t8.6\t99.0\t6.8\n",
      "\n",
      "100.0\t5.0\t100.0\t10.1\t100.0\t19.8\n",
      "100.0\t5.0\t100.0\t9.1\t100.0\t20.6\n",
      "99.0\t1.0\t100.0\t2.0\t99.0\t13.9\n",
      "99.0\t1.0\t100.0\t3.0\t99.0\t12.9\n",
      "wrapper fin!\n",
      "wrapper fin!\n",
      "process fin!\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Process\n",
    "\n",
    "# No point being fancy about setting up this list\n",
    "procs = []\n",
    "for fpath in [\"/tmp/movies.ndjson\", \"/tmp/movies2.ndjson\"]:\n",
    "    p = Process(target=MovieTable.records, args=(fpath, 500))\n",
    "    p.start()\n",
    "    procs.append(p)\n",
    "\n",
    "while True:\n",
    "    if not any(p.is_alive() for p in procs):\n",
    "        print(\"process fin!\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "264f330c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 50 records to /tmp/movies.ndjsonWriting 50 records to /tmp/movies2.ndjson\n",
      "\n",
      "89.1\t4.6\t83.5\t8.1\t87.9\t11.189.1\t4.6\t83.5\t8.1\t87.9\t11.1\n",
      "\n",
      "async dec fin!async dec fin!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Pool\n",
    "\n",
    "def run_async_pool(args):\n",
    "    asyncio.run(AMovieTable.records(*args))\n",
    "\n",
    "\n",
    "with Pool(2) as p:\n",
    "    p.map(run_async_pool, [(\"/tmp/movies.ndjson\", 50), (\"/tmp/movies2.ndjson\", 50)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e60aa9e",
   "metadata": {},
   "source": [
    "### Logging\n",
    "\n",
    "Don't forget about logging! As you can see, it's hard to tell what thread is producing any particular log line\n",
    "\n",
    "- pass an ID/name/any metadata that you might need to the method in question, and ensure that it logs using it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7373066d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def awith_cpu(func):\n",
    "    @functools.wraps(func)\n",
    "    async def wrapped(*args, **kwargs):\n",
    "        t = Timer(cpu, args[0]) # <---\n",
    "        t.task()\n",
    "\n",
    "        await func(*args, **kwargs)\n",
    "\n",
    "        await t.stop()\n",
    "        print(\"fin!\")\n",
    "    return wrapped\n",
    "\n",
    "class AMovieTable:\n",
    "    @awith_cpu\n",
    "    async def records(i, fpath, n_records=10):\n",
    "        print(f\"Writing {n_records} records to {fpath}\")\n",
    "        with open(fpath, \"w\") as ostream:\n",
    "            for _ in range(n_records):\n",
    "                print(gen_movie(), file=ostream) # Do work\n",
    "                await asyncio.sleep(0)           # Yield control to another thread\n",
    "\n",
    "\n",
    "def cpu(*args):\n",
    "    print(\" - \".join([str(args), \"\\t\".join(map(str, psutil.cpu_percent(percpu=True)))]), flush=True)\n",
    "\n",
    "def run_multiproc(nprocs):\n",
    "    fpaths = []\n",
    "    for i in range(nprocs):\n",
    "        fpaths.append((i, f'/tmp/movies_{i}.ndjson', 50))\n",
    "\n",
    "    with Pool(nprocs) as p:\n",
    "        p.map(run_async_pool, fpaths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ccdabb67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 50 records to /tmp/movies_0.ndjsonWriting 50 records to /tmp/movies_1.ndjson\n",
      "\n",
      "(1,) - 80.6\t13.6\t75.4\t7.8\t87.5\t11.0(0,) - 80.6\t13.7\t75.4\t7.8\t87.5\t11.0\n",
      "\n",
      "fin!\n",
      "fin!\n"
     ]
    }
   ],
   "source": [
    "run_multiproc(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f66100",
   "metadata": {},
   "source": [
    "## Thoughts on the GIL\n",
    "\n",
    "- Python process == 1 thread is analagous to microservices architecture (lambda)\n",
    "- This is easy to reason about and to design\n",
    "    - For a single thread, write code that ensures that the usage is saturated\n",
    "    - If you need parallel, simply take this same code and run it on another core (multiprocessing)\n",
    "\n",
    "The best way to demonstrate this is to take the same approach, and run it across every CPU thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "89d21252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 50 records to /tmp/movies_3.ndjsonWriting 50 records to /tmp/movies_1.ndjsonWriting 50 records to /tmp/movies_0.ndjson\n",
      "Writing 50 records to /tmp/movies_4.ndjsonWriting 50 records to /tmp/movies_2.ndjson\n",
      "\n",
      "\n",
      "Writing 50 records to /tmp/movies_5.ndjson\n",
      "\n",
      "(3,) - 81.7\t13.1\t71.7\t13.0\t81.5\t10.8\n",
      "(1,) - 81.7\t13.1\t71.7\t13.1\t81.5\t10.9(2,) - 81.7\t13.2\t71.7\t13.1\t81.5\t10.9\n",
      "\n",
      "(4,) - 81.7\t13.3\t71.6\t13.2\t81.5\t11.1\n",
      "(0,) - 81.8\t13.6\t71.8\t13.6\t81.6\t11.4(5,) - 81.8\t13.6\t71.8\t13.6\t81.6\t11.4\n",
      "\n",
      "fin!\n",
      "fin!\n",
      "fin!\n",
      "fin!\n",
      "fin!fin!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_multiproc(os.cpu_count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952effb5",
   "metadata": {},
   "source": [
    "We have now achieved **saturation**\n",
    "\n",
    "![Saturation!](tumblr_p47wmu8e3P1w1x3muo1_500.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81446f9b",
   "metadata": {},
   "source": [
    "## 2. Communication\n",
    "\n",
    "If possible, just don't communicate! Think about whether or not you _need_ to pass a result or value around\n",
    "\n",
    "But if you need to,\n",
    "\n",
    "### Example 2. Consider files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2999116",
   "metadata": {},
   "source": [
    "You can write to IO in async functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2ad5a6c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ab']\n"
     ]
    }
   ],
   "source": [
    "from io import StringIO\n",
    "\n",
    "async def a(ostream, chr):\n",
    "    ostream.write(chr)\n",
    "\n",
    "s = StringIO()\n",
    "asyncio.run(asyncio.gather(\n",
    "    a(s, 'a'),\n",
    "    a(s, 'b')\n",
    "))\n",
    "\n",
    "s.seek(0)\n",
    "print(s.readlines())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63723ef4",
   "metadata": {},
   "source": [
    "You can also read from them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c22f4abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = StringIO('''asdfsdf\n",
    "234234\n",
    "oeairjl\n",
    "3049568\n",
    "er;ij\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d8381f63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 asdfsdf\n",
      "\n",
      "2 234234\n",
      "\n",
      "3 oeairjl\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "async def b(istream, i):\n",
    "    l = istream.readline()\n",
    "    await asyncio.sleep(0)\n",
    "    print(i, l)\n",
    "\n",
    "asyncio.run(asyncio.gather(b(s, 1), b(s, 2), b(s, 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6920e51",
   "metadata": {},
   "source": [
    "You might notice that `asyncio.gather` returns the results of the async tasks.\n",
    "\n",
    "Unfortunately, using `gather` with _many_ async tasks results in memory blowout, so using gather is usually not advised unless you know the number/size of results is low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6cebbbc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 /tmp/movies.ndjson\n"
     ]
    }
   ],
   "source": [
    "!wc -l /tmp/movies.ndjson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "72e609ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = asyncio.Queue(2)\n",
    "\n",
    "class Sentinel(): pass\n",
    "\n",
    "async def producer(q, istream, sentinel=Sentinel):\n",
    "    for line in istream:\n",
    "        await q.put(line)\n",
    "    await q.put(sentinel)\n",
    "\n",
    "async def consumer(q, ostream, sentinel=Sentinel):\n",
    "    while True:\n",
    "        d = await q.get()\n",
    "        if d == sentinel:\n",
    "            await q.put(sentinel)\n",
    "            return\n",
    "        data = json.loads(d)[\"title\"]\n",
    "        await asyncio.sleep(0)\n",
    "        print(data, file=ostream)\n",
    "\n",
    "\n",
    "def run_queue(qsize):\n",
    "    q = asyncio.Queue(qsize)\n",
    "    with open(\"/tmp/movies.ndjson\") as istream, open(\"/tmp/movie_titles.txt\", \"w\") as ostream:\n",
    "        asyncio.run(asyncio.gather(\n",
    "            producer(q, istream),\n",
    "            consumer(q, ostream),\n",
    "        ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4a8c0382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.01 ms ± 1.48 ms per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "5.13 ms ± 1.32 ms per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "3.44 ms ± 815 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit run_queue(2)\n",
    "%timeit run_queue(20)\n",
    "%timeit run_queue(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "04b0731c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   50 /tmp/movie_titles.txt\n",
      "   50 /tmp/movies.ndjson\n",
      "  100 total\n",
      "Public-key modular info-mediaries\n",
      "Diverse disintermediate approach\n",
      "User-friendly intermediate hardware\n"
     ]
    }
   ],
   "source": [
    "!wc -l /tmp/movie_titles.txt /tmp/movies.ndjson && head -n 3 /tmp/movie_titles.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38835465",
   "metadata": {},
   "source": [
    "## Example 3: Extending the standard lib\n",
    "\n",
    "This should always be your first port of call when prototyping something in Python. Python has a pattern of not implementing \"framework\" features and patterns, but it gives you the tools to start your own.\n",
    "\n",
    "*Remember - every python async framework is written in python*\n",
    "\n",
    "For this example, I tried to tackle the problem of controlling async requests by a \"rate limit\".\n",
    "\n",
    "I haven't gone whole-hog and implemented the queue producer, I've just used files instead. The key part to look at would be the different ThrottledQueue instantiations, and the producer/consumer combos that use them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "56fe089f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ThrottledQueue(asyncio.Queue):\n",
    "    \"subclass asyncio.Queue i.e. import all behaviour\"\n",
    "\n",
    "    def __init__(self, per_second, maxsize=0, *, loop=None, i=0):\n",
    "        \"Set up some extra vars and then call the original init\"\n",
    "\n",
    "        self.i = i\n",
    "        self.per_second = per_second\n",
    "        self.last_get = time.time() # this is the fastest way... I think?\n",
    "        super(ThrottledQueue, self).__init__(maxsize=maxsize, loop=loop)\n",
    "\n",
    "    async def get(self):\n",
    "        \"Throttles, sleep \"\n",
    "\n",
    "        elapsed = time.time() - self.last_get\n",
    "        sleep_time = self.per_second - elapsed\n",
    "        print(self.i, '- times', f'{elapsed:.5f}', f'{sleep_time:.5f}', '- sizes', self.qsize(), f'{self.qsize() / self.maxsize:.5f}')\n",
    "        await asyncio.sleep(max(0, sleep_time)) # Make sure we wait at least 0 seconds\n",
    "\n",
    "        result = await super(ThrottledQueue, self).get()\n",
    "\n",
    "        self.last_get = time.time()\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b5716d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_queue(per_second, qsize):\n",
    "    q = ThrottledQueue(per_second, qsize)\n",
    "    with open(\"/tmp/movies.ndjson\") as istream, open(\"/tmp/movie_titles.txt\", \"w\") as ostream:\n",
    "        asyncio.run(asyncio.gather(\n",
    "            producer(q, istream), # <-- queue in\n",
    "            consumer(q, ostream), # <-- queue out\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d973e017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 - times 0.00506 0.09494 - sizes 20 1.00000\n",
      "0 - times 0.00030 0.09970 - sizes 20 1.00000\n",
      "0 - times 0.00028 0.09972 - sizes 20 1.00000\n",
      "0 - times 0.00020 0.09980 - sizes 20 1.00000\n",
      "0 - times 0.00021 0.09979 - sizes 20 1.00000\n",
      "0 - times 0.00017 0.09983 - sizes 20 1.00000\n",
      "0 - times 0.00050 0.09950 - sizes 20 1.00000\n",
      "0 - times 0.00015 0.09985 - sizes 20 1.00000\n",
      "0 - times 0.00026 0.09974 - sizes 20 1.00000\n",
      "0 - times 0.00059 0.09941 - sizes 20 1.00000\n",
      "0 - times 0.00036 0.09964 - sizes 20 1.00000\n",
      "0 - times 0.00018 0.09982 - sizes 20 1.00000\n",
      "0 - times 0.00013 0.09987 - sizes 20 1.00000\n",
      "0 - times 0.00026 0.09974 - sizes 20 1.00000\n",
      "0 - times 0.00016 0.09984 - sizes 20 1.00000\n",
      "0 - times 0.00031 0.09969 - sizes 20 1.00000\n",
      "0 - times 0.00016 0.09984 - sizes 20 1.00000\n",
      "0 - times 0.00026 0.09974 - sizes 20 1.00000\n",
      "0 - times 0.00029 0.09971 - sizes 20 1.00000\n",
      "0 - times 0.00013 0.09987 - sizes 20 1.00000\n",
      "0 - times 0.00013 0.09987 - sizes 20 1.00000\n",
      "0 - times 0.00022 0.09978 - sizes 20 1.00000\n",
      "0 - times 0.00036 0.09964 - sizes 20 1.00000\n",
      "0 - times 0.00032 0.09968 - sizes 20 1.00000\n",
      "0 - times 0.00015 0.09985 - sizes 20 1.00000\n",
      "0 - times 0.00015 0.09985 - sizes 20 1.00000\n",
      "0 - times 0.00206 0.09794 - sizes 20 1.00000\n",
      "0 - times 0.00023 0.09977 - sizes 20 1.00000\n",
      "0 - times 0.00016 0.09984 - sizes 20 1.00000\n",
      "0 - times 0.00016 0.09984 - sizes 20 1.00000\n",
      "0 - times 0.00045 0.09955 - sizes 20 1.00000\n",
      "0 - times 0.00055 0.09945 - sizes 20 1.00000\n",
      "0 - times 0.00022 0.09978 - sizes 19 0.95000\n",
      "0 - times 0.00016 0.09984 - sizes 18 0.90000\n",
      "0 - times 0.00012 0.09988 - sizes 17 0.85000\n",
      "0 - times 0.00013 0.09987 - sizes 16 0.80000\n",
      "0 - times 0.00010 0.09990 - sizes 15 0.75000\n",
      "0 - times 0.00021 0.09979 - sizes 14 0.70000\n",
      "0 - times 0.00012 0.09988 - sizes 13 0.65000\n",
      "0 - times 0.00015 0.09985 - sizes 12 0.60000\n",
      "0 - times 0.00024 0.09976 - sizes 11 0.55000\n",
      "0 - times 0.00018 0.09982 - sizes 10 0.50000\n",
      "0 - times 0.00022 0.09978 - sizes 9 0.45000\n",
      "0 - times 0.00019 0.09981 - sizes 8 0.40000\n",
      "0 - times 0.00032 0.09968 - sizes 7 0.35000\n",
      "0 - times 0.00019 0.09981 - sizes 6 0.30000\n",
      "0 - times 0.00028 0.09972 - sizes 5 0.25000\n",
      "0 - times 0.00021 0.09979 - sizes 4 0.20000\n",
      "0 - times 0.00011 0.09989 - sizes 3 0.15000\n",
      "0 - times 0.00020 0.09980 - sizes 2 0.10000\n",
      "0 - times 0.00022 0.09978 - sizes 1 0.05000\n",
      "--\n",
      "0 - times 0.00091 0.99909 - sizes 2 1.00000\n",
      "0 - times 0.00033 0.99967 - sizes 2 1.00000\n",
      "0 - times 0.00032 0.99968 - sizes 2 1.00000\n",
      "0 - times 0.00022 0.99978 - sizes 2 1.00000\n",
      "0 - times 0.00025 0.99975 - sizes 2 1.00000\n",
      "0 - times 0.00023 0.99977 - sizes 2 1.00000\n",
      "0 - times 0.00055 0.99945 - sizes 2 1.00000\n",
      "0 - times 0.00026 0.99974 - sizes 2 1.00000\n",
      "0 - times 0.00020 0.99980 - sizes 2 1.00000\n",
      "0 - times 0.00022 0.99978 - sizes 2 1.00000\n",
      "0 - times 0.00026 0.99974 - sizes 2 1.00000\n",
      "0 - times 0.00023 0.99977 - sizes 2 1.00000\n",
      "0 - times 0.00021 0.99979 - sizes 2 1.00000\n",
      "0 - times 0.00026 0.99974 - sizes 2 1.00000\n",
      "0 - times 0.00020 0.99980 - sizes 2 1.00000\n",
      "0 - times 0.00017 0.99983 - sizes 2 1.00000\n",
      "0 - times 0.00024 0.99976 - sizes 2 1.00000\n",
      "0 - times 0.00014 0.99986 - sizes 2 1.00000\n",
      "0 - times 0.00017 0.99983 - sizes 2 1.00000\n",
      "0 - times 0.00017 0.99983 - sizes 2 1.00000\n",
      "0 - times 0.00038 0.99962 - sizes 2 1.00000\n",
      "0 - times 0.00019 0.99981 - sizes 2 1.00000\n",
      "0 - times 0.00048 0.99952 - sizes 2 1.00000\n",
      "0 - times 0.00024 0.99976 - sizes 2 1.00000\n",
      "0 - times 0.00049 0.99951 - sizes 2 1.00000\n",
      "0 - times 0.00014 0.99986 - sizes 2 1.00000\n",
      "0 - times 0.00029 0.99971 - sizes 2 1.00000\n",
      "0 - times 0.00027 0.99973 - sizes 2 1.00000\n",
      "0 - times 0.00021 0.99979 - sizes 2 1.00000\n",
      "0 - times 0.00025 0.99975 - sizes 2 1.00000\n",
      "0 - times 0.00026 0.99974 - sizes 2 1.00000\n",
      "0 - times 0.00019 0.99981 - sizes 2 1.00000\n",
      "0 - times 0.00019 0.99981 - sizes 2 1.00000\n",
      "0 - times 0.00035 0.99965 - sizes 2 1.00000\n",
      "0 - times 0.00011 0.99989 - sizes 2 1.00000\n",
      "0 - times 0.00012 0.99988 - sizes 2 1.00000\n",
      "0 - times 0.00018 0.99982 - sizes 2 1.00000\n",
      "0 - times 0.00016 0.99984 - sizes 2 1.00000\n",
      "0 - times 0.00027 0.99973 - sizes 2 1.00000\n",
      "0 - times 0.00042 0.99958 - sizes 2 1.00000\n",
      "0 - times 0.00024 0.99976 - sizes 2 1.00000\n",
      "0 - times 0.00016 0.99984 - sizes 2 1.00000\n",
      "0 - times 0.00019 0.99981 - sizes 2 1.00000\n",
      "0 - times 0.00021 0.99979 - sizes 2 1.00000\n",
      "0 - times 0.00040 0.99960 - sizes 2 1.00000\n",
      "0 - times 0.00017 0.99983 - sizes 2 1.00000\n",
      "0 - times 0.00024 0.99976 - sizes 2 1.00000\n",
      "0 - times 0.00021 0.99979 - sizes 2 1.00000\n",
      "0 - times 0.00033 0.99967 - sizes 2 1.00000\n",
      "0 - times 0.00017 0.99983 - sizes 2 1.00000\n",
      "0 - times 0.00016 0.99984 - sizes 1 0.50000\n"
     ]
    }
   ],
   "source": [
    "run_queue(0.1, 20)\n",
    "print('--')\n",
    "run_queue(1, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573dea94",
   "metadata": {},
   "source": [
    "Okay... how about >1 queue?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "695b2289",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_queues(per_second, per_second2, qsize):\n",
    "    q = ThrottledQueue(per_second, qsize, i=1)\n",
    "    q2 = ThrottledQueue(per_second2, qsize, i=2)\n",
    "    with open(\"/tmp/movies.ndjson\") as istream, open(\"/tmp/movies_2.ndjson\") as istream2, open(\"/tmp/movie_titles.txt\", \"w\") as ostream:\n",
    "        asyncio.run(asyncio.gather(\n",
    "            producer(q, istream), producer(q2, istream2), # <-- q1 & q2 in\n",
    "            consumer(q, ostream), consumer(q2, ostream),  # <-- q1 & q2 out\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f5abd05f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 - times 0.00204 0.09796 - sizes 20 1.00000\n",
      "2 - times 0.00292 0.04708 - sizes 20 1.00000\n",
      "2 - times 0.00019 0.04981 - sizes 20 1.00000\n",
      "1 - times 0.00068 0.09932 - sizes 20 1.00000\n",
      "2 - times 0.00100 0.04900 - sizes 20 1.00000\n",
      "2 - times 0.00024 0.04976 - sizes 20 1.00000\n",
      "1 - times 0.00017 0.09983 - sizes 20 1.00000\n",
      "2 - times 0.00023 0.04977 - sizes 20 1.00000\n",
      "2 - times 0.00016 0.04984 - sizes 20 1.00000\n",
      "1 - times 0.00017 0.09983 - sizes 20 1.00000\n",
      "2 - times 0.00017 0.04983 - sizes 20 1.00000\n",
      "2 - times 0.00026 0.04974 - sizes 20 1.00000\n",
      "1 - times 0.00013 0.09987 - sizes 20 1.00000\n",
      "2 - times 0.00017 0.04983 - sizes 20 1.00000\n",
      "2 - times 0.00022 0.04978 - sizes 20 1.00000\n",
      "1 - times 0.00026 0.09974 - sizes 20 1.00000\n",
      "2 - times 0.00021 0.04979 - sizes 20 1.00000\n",
      "2 - times 0.00021 0.04979 - sizes 20 1.00000\n",
      "1 - times 0.00014 0.09986 - sizes 20 1.00000\n",
      "2 - times 0.00018 0.04982 - sizes 20 1.00000\n",
      "2 - times 0.00039 0.04961 - sizes 20 1.00000\n",
      "1 - times 0.00018 0.09982 - sizes 20 1.00000\n",
      "2 - times 0.00021 0.04979 - sizes 20 1.00000\n",
      "2 - times 0.00024 0.04976 - sizes 20 1.00000\n",
      "1 - times 0.00014 0.09986 - sizes 20 1.00000\n",
      "2 - times 0.00012 0.04988 - sizes 20 1.00000\n",
      "2 - times 0.00013 0.04987 - sizes 20 1.00000\n",
      "1 - times 0.00015 0.09985 - sizes 20 1.00000\n",
      "2 - times 0.00015 0.04985 - sizes 20 1.00000\n",
      "2 - times 0.00023 0.04977 - sizes 20 1.00000\n",
      "1 - times 0.00012 0.09988 - sizes 20 1.00000\n",
      "2 - times 0.00021 0.04979 - sizes 20 1.00000\n",
      "2 - times 0.00024 0.04976 - sizes 20 1.00000\n",
      "1 - times 0.00020 0.09980 - sizes 20 1.00000\n",
      "2 - times 0.00026 0.04974 - sizes 20 1.00000\n",
      "2 - times 0.00064 0.04936 - sizes 20 1.00000\n",
      "1 - times 0.00015 0.09985 - sizes 20 1.00000\n",
      "2 - times 0.00045 0.04955 - sizes 20 1.00000\n",
      "2 - times 0.00012 0.04988 - sizes 20 1.00000\n",
      "1 - times 0.00035 0.09965 - sizes 20 1.00000\n",
      "2 - times 0.00036 0.04964 - sizes 20 1.00000\n",
      "2 - times 0.00023 0.04977 - sizes 20 1.00000\n",
      "1 - times 0.00015 0.09985 - sizes 20 1.00000\n",
      "2 - times 0.00024 0.04976 - sizes 20 1.00000\n",
      "2 - times 0.00025 0.04975 - sizes 20 1.00000\n",
      "1 - times 0.00019 0.09981 - sizes 20 1.00000\n",
      "2 - times 0.00025 0.04975 - sizes 20 1.00000\n",
      "2 - times 0.00148 0.04852 - sizes 20 1.00000\n",
      "1 - times 0.00167 0.09833 - sizes 20 1.00000\n",
      "2 - times 0.00020 0.04980 - sizes 19 0.95000\n",
      "1 - times 0.00042 0.09958 - sizes 20 1.00000\n",
      "2 - times 0.00084 0.04916 - sizes 18 0.90000\n",
      "2 - times 0.00009 0.04991 - sizes 17 0.85000\n",
      "1 - times 0.00026 0.09974 - sizes 20 1.00000\n",
      "2 - times 0.00013 0.04987 - sizes 16 0.80000\n",
      "2 - times 0.00020 0.04980 - sizes 15 0.75000\n",
      "1 - times 0.00057 0.09943 - sizes 20 1.00000\n",
      "2 - times 0.00013 0.04987 - sizes 14 0.70000\n",
      "2 - times 0.00015 0.04985 - sizes 13 0.65000\n",
      "1 - times 0.00018 0.09982 - sizes 20 1.00000\n",
      "2 - times 0.00014 0.04986 - sizes 12 0.60000\n",
      "2 - times 0.00012 0.04988 - sizes 11 0.55000\n",
      "1 - times 0.00015 0.09985 - sizes 20 1.00000\n",
      "2 - times 0.00016 0.04984 - sizes 10 0.50000\n",
      "2 - times 0.00012 0.04988 - sizes 9 0.45000\n",
      "1 - times 0.00062 0.09938 - sizes 20 1.00000\n",
      "2 - times 0.00027 0.04973 - sizes 8 0.40000\n",
      "2 - times 0.00178 0.04822 - sizes 7 0.35000\n",
      "1 - times 0.00043 0.09957 - sizes 20 1.00000\n",
      "2 - times 0.00011 0.04989 - sizes 6 0.30000\n",
      "2 - times 0.00015 0.04985 - sizes 5 0.25000\n",
      "1 - times 0.00015 0.09985 - sizes 20 1.00000\n",
      "2 - times 0.00009 0.04991 - sizes 4 0.20000\n",
      "2 - times 0.00014 0.04986 - sizes 3 0.15000\n",
      "1 - times 0.00052 0.09948 - sizes 20 1.00000\n",
      "2 - times 0.00026 0.04974 - sizes 2 0.10000\n",
      "2 - times 0.00016 0.04984 - sizes 1 0.05000\n",
      "1 - times 0.00027 0.09973 - sizes 20 1.00000\n",
      "1 - times 0.00035 0.09965 - sizes 20 1.00000\n",
      "1 - times 0.00024 0.09976 - sizes 20 1.00000\n",
      "1 - times 0.00016 0.09984 - sizes 20 1.00000\n",
      "1 - times 0.00032 0.09968 - sizes 20 1.00000\n",
      "1 - times 0.00022 0.09978 - sizes 20 1.00000\n",
      "1 - times 0.00063 0.09937 - sizes 19 0.95000\n",
      "1 - times 0.00011 0.09989 - sizes 18 0.90000\n",
      "1 - times 0.00020 0.09980 - sizes 17 0.85000\n",
      "1 - times 0.00011 0.09989 - sizes 16 0.80000\n",
      "1 - times 0.00010 0.09990 - sizes 15 0.75000\n",
      "1 - times 0.00017 0.09983 - sizes 14 0.70000\n",
      "1 - times 0.00014 0.09986 - sizes 13 0.65000\n",
      "1 - times 0.00011 0.09989 - sizes 12 0.60000\n",
      "1 - times 0.00021 0.09979 - sizes 11 0.55000\n",
      "1 - times 0.00025 0.09975 - sizes 10 0.50000\n",
      "1 - times 0.00009 0.09991 - sizes 9 0.45000\n",
      "1 - times 0.00013 0.09987 - sizes 8 0.40000\n",
      "1 - times 0.00016 0.09984 - sizes 7 0.35000\n",
      "1 - times 0.00019 0.09981 - sizes 6 0.30000\n",
      "1 - times 0.00019 0.09981 - sizes 5 0.25000\n",
      "1 - times 0.00011 0.09989 - sizes 4 0.20000\n",
      "1 - times 0.00016 0.09984 - sizes 3 0.15000\n",
      "1 - times 0.00013 0.09987 - sizes 2 0.10000\n",
      "1 - times 0.00019 0.09981 - sizes 1 0.05000\n"
     ]
    }
   ],
   "source": [
    "run_queues(0.1, 0.05, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0845f122",
   "metadata": {},
   "source": [
    "Okay... but what if I wanted to be able to retry items? That would violate the overall rate limit.\n",
    "\n",
    "- Add a method onto the queue that just performs the usual throttle sleep, and blocks the get() method from releasing any new items as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cf5f7344",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ThrottledQueue(asyncio.Queue):\n",
    "    \"subclass asyncio.Queue i.e. import all behaviour\"\n",
    "\n",
    "    def __init__(self, per_second, maxsize=0, *, loop=None, i=0):\n",
    "        \"Set up some extra vars and then call the original init\"\n",
    "\n",
    "        self.lock = asyncio.Lock()\n",
    "        self.i = i\n",
    "        self.per_second = per_second\n",
    "        self.last_get = time.time() # this is the fastest way... I think?\n",
    "        super(ThrottledQueue, self).__init__(maxsize=maxsize, loop=loop)\n",
    "\n",
    "    async def retry(self):\n",
    "        \"\"\"\n",
    "        Signals to the queue that an item is being retried, \n",
    "        so pause any get()s by aquiring the lock and throttling before releasing\n",
    "        \"\"\"\n",
    "        async with self.lock:\n",
    "            await self._throttle()\n",
    "\n",
    "    async def get(self):\n",
    "        async with self.lock:\n",
    "            await self._throttle()\n",
    "            result = await super(ThrottledQueue, self).get()\n",
    "\n",
    "            self.last_get = time.time()\n",
    "            return result\n",
    "\n",
    "    async def _throttle(self):\n",
    "        elapsed = time.time() - self.last_get\n",
    "        sleep_time = self.per_second - elapsed\n",
    "        print(self.i, '- times', f'{elapsed:.5f}', f'{sleep_time:.5f}', '- sizes', self.qsize(), f'{self.qsize() / self.maxsize:.5f}')\n",
    "        await asyncio.sleep(max(0, sleep_time)) # Make sure we wait at least 0 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "86c1c27d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 - times 0.00567 0.09433 - sizes 20 1.00000\n",
      "2 - times 0.00710 0.04290 - sizes 20 1.00000\n",
      "2 - times 0.00046 0.04954 - sizes 20 1.00000\n",
      "1 - times 0.00050 0.09950 - sizes 20 1.00000\n",
      "2 - times 0.00018 0.04982 - sizes 20 1.00000\n",
      "2 - times 0.00036 0.04964 - sizes 20 1.00000\n",
      "1 - times 0.00017 0.09983 - sizes 20 1.00000\n",
      "2 - times 0.00020 0.04980 - sizes 20 1.00000\n",
      "2 - times 0.00043 0.04957 - sizes 20 1.00000\n",
      "1 - times 0.00017 0.09983 - sizes 20 1.00000\n",
      "2 - times 0.00013 0.04987 - sizes 20 1.00000\n",
      "2 - times 0.00033 0.04967 - sizes 20 1.00000\n",
      "1 - times 0.00017 0.09983 - sizes 20 1.00000\n",
      "2 - times 0.00011 0.04989 - sizes 20 1.00000\n",
      "2 - times 0.00038 0.04962 - sizes 20 1.00000\n",
      "1 - times 0.00034 0.09966 - sizes 20 1.00000\n",
      "2 - times 0.00023 0.04977 - sizes 20 1.00000\n",
      "2 - times 0.00018 0.04982 - sizes 20 1.00000\n",
      "1 - times 0.00024 0.09976 - sizes 20 1.00000\n",
      "2 - times 0.00015 0.04985 - sizes 20 1.00000\n",
      "2 - times 0.00018 0.04982 - sizes 20 1.00000\n",
      "1 - times 0.00018 0.09982 - sizes 20 1.00000\n",
      "2 - times 0.00017 0.04983 - sizes 20 1.00000\n",
      "2 - times 0.00023 0.04977 - sizes 20 1.00000\n",
      "1 - times 0.00021 0.09979 - sizes 20 1.00000\n",
      "2 - times 0.00044 0.04956 - sizes 20 1.00000\n",
      "2 - times 0.00014 0.04986 - sizes 20 1.00000\n",
      "1 - times 0.00021 0.09979 - sizes 20 1.00000\n",
      "2 - times 0.00021 0.04979 - sizes 20 1.00000\n",
      "2 - times 0.00022 0.04978 - sizes 20 1.00000\n",
      "1 - times 0.00018 0.09982 - sizes 20 1.00000\n",
      "2 - times 0.00035 0.04965 - sizes 20 1.00000\n",
      "2 - times 0.00024 0.04976 - sizes 20 1.00000\n",
      "1 - times 0.00019 0.09981 - sizes 20 1.00000\n",
      "2 - times 0.00031 0.04969 - sizes 20 1.00000\n",
      "2 - times 0.00018 0.04982 - sizes 20 1.00000\n",
      "1 - times 0.00018 0.09982 - sizes 20 1.00000\n",
      "2 - times 0.00013 0.04987 - sizes 20 1.00000\n",
      "2 - times 0.00030 0.04970 - sizes 20 1.00000\n",
      "1 - times 0.00037 0.09963 - sizes 20 1.00000\n",
      "2 - times 0.00051 0.04949 - sizes 20 1.00000\n",
      "2 - times 0.00012 0.04988 - sizes 20 1.00000\n",
      "1 - times 0.00016 0.09984 - sizes 20 1.00000\n",
      "2 - times 0.00069 0.04931 - sizes 20 1.00000\n",
      "2 - times 0.00014 0.04986 - sizes 20 1.00000\n",
      "1 - times 0.00013 0.09987 - sizes 20 1.00000\n",
      "2 - times 0.00026 0.04974 - sizes 20 1.00000\n",
      "2 - times 0.00022 0.04978 - sizes 20 1.00000\n",
      "1 - times 0.00077 0.09923 - sizes 20 1.00000\n",
      "2 - times 0.00010 0.04990 - sizes 19 0.95000\n",
      "2 - times 0.00015 0.04985 - sizes 18 0.90000\n",
      "1 - times 0.00013 0.09987 - sizes 20 1.00000\n",
      "2 - times 0.00010 0.04990 - sizes 17 0.85000\n",
      "2 - times 0.00011 0.04989 - sizes 16 0.80000\n",
      "1 - times 0.00184 0.09816 - sizes 20 1.00000\n",
      "2 - times 0.00016 0.04984 - sizes 15 0.75000\n",
      "2 - times 0.00021 0.04979 - sizes 14 0.70000\n",
      "1 - times 0.00014 0.09986 - sizes 20 1.00000\n",
      "2 - times 0.00014 0.04986 - sizes 13 0.65000\n",
      "2 - times 0.00012 0.04988 - sizes 12 0.60000\n",
      "1 - times 0.00093 0.09907 - sizes 20 1.00000\n",
      "2 - times 0.00013 0.04987 - sizes 11 0.55000\n",
      "2 - times 0.00046 0.04954 - sizes 10 0.50000\n",
      "1 - times 0.00014 0.09986 - sizes 20 1.00000\n",
      "2 - times 0.00054 0.04946 - sizes 9 0.45000\n",
      "2 - times 0.00010 0.04990 - sizes 8 0.40000\n",
      "1 - times 0.00020 0.09980 - sizes 20 1.00000\n",
      "2 - times 0.00026 0.04974 - sizes 7 0.35000\n",
      "2 - times 0.00017 0.04983 - sizes 6 0.30000\n",
      "1 - times 0.00023 0.09977 - sizes 20 1.00000\n",
      "2 - times 0.00017 0.04983 - sizes 5 0.25000\n",
      "2 - times 0.00022 0.04978 - sizes 4 0.20000\n",
      "1 - times 0.00020 0.09980 - sizes 20 1.00000\n",
      "2 - times 0.00013 0.04987 - sizes 3 0.15000\n",
      "1 - times 0.00025 0.09975 - sizes 20 1.00000\n",
      "2 - times 0.00056 0.04944 - sizes 2 0.10000\n",
      "2 - times 0.00014 0.04986 - sizes 1 0.05000\n",
      "1 - times 0.00047 0.09953 - sizes 20 1.00000\n",
      "1 - times 0.00020 0.09980 - sizes 20 1.00000\n",
      "1 - times 0.00040 0.09960 - sizes 20 1.00000\n",
      "1 - times 0.00074 0.09926 - sizes 20 1.00000\n",
      "1 - times 0.00023 0.09977 - sizes 20 1.00000\n",
      "1 - times 0.00040 0.09960 - sizes 20 1.00000\n",
      "1 - times 0.00078 0.09922 - sizes 19 0.95000\n",
      "1 - times 0.00028 0.09972 - sizes 18 0.90000\n",
      "1 - times 0.00013 0.09987 - sizes 17 0.85000\n",
      "1 - times 0.00020 0.09980 - sizes 16 0.80000\n",
      "1 - times 0.00010 0.09990 - sizes 15 0.75000\n",
      "1 - times 0.00011 0.09989 - sizes 14 0.70000\n",
      "1 - times 0.00019 0.09981 - sizes 13 0.65000\n",
      "1 - times 0.00018 0.09982 - sizes 12 0.60000\n",
      "1 - times 0.00019 0.09981 - sizes 11 0.55000\n",
      "1 - times 0.00019 0.09981 - sizes 10 0.50000\n",
      "1 - times 0.00019 0.09981 - sizes 9 0.45000\n",
      "1 - times 0.00017 0.09983 - sizes 8 0.40000\n",
      "1 - times 0.00010 0.09990 - sizes 7 0.35000\n",
      "1 - times 0.00017 0.09983 - sizes 6 0.30000\n",
      "1 - times 0.00022 0.09978 - sizes 5 0.25000\n",
      "1 - times 0.00087 0.09913 - sizes 4 0.20000\n",
      "1 - times 0.00086 0.09914 - sizes 3 0.15000\n",
      "1 - times 0.00026 0.09974 - sizes 2 0.10000\n",
      "1 - times 0.00013 0.09987 - sizes 1 0.05000\n"
     ]
    }
   ],
   "source": [
    "run_queues(0.1, 0.05, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0e8c3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
